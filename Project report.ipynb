{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **MiniHack KeyRoom KB**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Author**: Riccardo Parente\\\n",
        "**Course**: Artificial Intelligence Fundamentals 2023/2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Introduction**\n",
        "\n",
        "The goal of this project is to implement a knowledge base written in Prolog and to use it to resolve the puzzle given by the \"KeyRoom\" environment of the MiniHack Environment Zoo. In this environment the agent must find a key to unlock a door, enter the room and go to the exit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Requirements**\n",
        "To run the project with its software dependencies on Google Colab (used also for the assessment) the following commands must be runned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!sudo apt update\n",
        "!sudo apt install -y build-essential autoconf libtool pkg-config python3-dev \\\n",
        "    python3-pip python3-numpy git flex bison libbz2-dev\n",
        "\n",
        "!wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | sudo apt-key add -\n",
        "!sudo apt-add-repository 'deb https://apt.kitware.com/ubuntu/ bionic main'\n",
        "!sudo apt-get update && apt-get --allow-unauthenticated install -y \\\n",
        "    cmake \\\n",
        "    kitware-archive-keyring\n",
        "\n",
        "!sudo rm $(which cmake)\n",
        "!$(which cmake) --version\n",
        "\n",
        "!sudo apt install swi-prolog\n",
        "\n",
        "!pip3 install -U nle\n",
        "!pip install minihack\n",
        "!pip install pyswip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0j8o7XJ5HuZ4"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import minihack\n",
        "from pyswip import Prolog\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import IPython.display as display\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Knowledge base**\n",
        "The knowledge base was constructed exploiting the knowledge of the environment, creating an `action(X)` for each possible action X permitted in the environment: in particular, all movement actions were grouped into the two predicates `action(move_towards_goal(Direction))` and `action(move(Direction))` to take advantage of the unification of the direction; the first one was used when the agent knew where the current goal was and the second one when some exploration was needed, since the environment is partially observable. Additionally the actions were ordered by priority.\\\n",
        "The predicate `next_goal(Goal)` unifies the current sub-goal of the puzzle (find the key, open the door, enter the room, escape), using the `has/2`, `is_closed/1` and `has_entered/0` predicates.\\\n",
        "Some knowledge of the NetHack game was also needed to add some logic (`close_direction_door(R, C, D, Direction)`) to enter the room behind the door since in the game a door cannot be traversed diagonally.\n",
        "To track the structure of the room and the position of every important element of the environment, including the agent, the `position/3` predicate was used. Also, to avoid the agent entering a loop of movements, the `explored/2` predicate was used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Methodology**\n",
        "Each \"run\" of the problem (i.e. each time `env.reset()` is called) was limited in the number of steps, to avoid endless runs. Also each time the knowledge base was \"cleaned\" of all the predicates that were inserted during the execution.\\\n",
        "In each step the first operation is the parsing of the current state (`process_state`) where predicates are inserted in the knowledge base according to the observation received. The knowledge base is then queried for the action to perform and the first action, the one with the most priority, is chosen; finally the action is performed and the step ends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "tLECr3NQIIes"
      },
      "outputs": [],
      "source": [
        "NUM_EPISODES = 100\n",
        "is_little = True\n",
        "def_file = \"MiniHack-KeyRoom-S15-v0\"\n",
        "if (is_little):\n",
        "    def_file = \"MiniHack-KeyRoom-S5-v0\"\n",
        "KB = Prolog()\n",
        "KB.consult(\"kb.pl\")\n",
        "KB.retractall(\"has(agent, _)\")\n",
        "KB.retractall(\"explored(_,_)\")\n",
        "KB.assertz(\"is_closed(door)\")\n",
        "env = gym.make(def_file, observation_keys=(\"screen_descriptions\",\"chars\", \"pixel\", \"inv_strs\", \"message\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "vJ4TGPmEwvad",
        "outputId": "d9da78eb-27c7-4bb9-e7f7-a817ff04e402"
      },
      "outputs": [],
      "source": [
        "total_reward = 0\n",
        "total_steps = 0\n",
        "for episode in range(NUM_EPISODES):\n",
        "    steps = 0\n",
        "    reward = 0\n",
        "    ep_states = []\n",
        "    state = env.reset()\n",
        "    ep_states.append(state['pixel'])\n",
        "    done = False\n",
        "    while not done and steps < 50:\n",
        "        process_state(KB, state)\n",
        "        try:\n",
        "            action = list(KB.query('action(X)'))[0]['X']\n",
        "            print(action)\n",
        "        except Exception as e:\n",
        "            action = None\n",
        "\n",
        "        if action:\n",
        "            state, reward, done, info = env.step(get_action(action))\n",
        "            if action == \"pick\":\n",
        "                KB.assertz(\"has(agent, key)\")\n",
        "                KB.retractall(\"explored(_,_)\")\n",
        "            elif action == \"open_door\":\n",
        "                KB.retractall(\"is_closed(_)\")\n",
        "                KB.retractall(\"explored(_,_)\")\n",
        "            ep_states.append(state['pixel'])\n",
        "        else:\n",
        "            print(\"ERROR: impossible to perform any action.\")\n",
        "            break\n",
        "\n",
        "        steps += 1\n",
        "\n",
        "    plot_sequence(ep_states, is_little)\n",
        "    plt.imshow(ep_states[-1][115:275, 480:750] if is_little else ep_states[-1][50:325, 480:800])\n",
        "    print(f'Episode {episode} - {steps} steps')\n",
        "    print(f'Final reward: {reward}')\n",
        "    time.sleep(0.75)\n",
        "    KB.retractall(\"has(agent, _)\")\n",
        "    KB.retractall(\"explored(_,_)\")\n",
        "    KB.retractall(\"position(_,_,_)\")\n",
        "    KB.retractall(\"has_entered(_)\")\n",
        "    KB.assertz(\"is_closed(door)\")\n",
        "    total_reward += reward\n",
        "    if (reward != 0):\n",
        "        total_steps += steps\n",
        "\n",
        "print(f'After {NUM_EPISODES} episodes, mean reward is {total_reward/NUM_EPISODES}')\n",
        "if (total_reward != 0):\n",
        "    print(f'After {NUM_EPISODES} episodes, mean steps is {total_steps/total_reward}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Assessment**\n",
        "The assessment has been conducted running 100 random generated instances of the four main KeyRoom variants made available by the MiniHack environment.\\\n",
        "The main factor analyzed was the success rate, that is whether the agent reached the final goal in less than 50 steps, that was considered a reasonable number for each variation of the problem. Also the mean steps needed to reach the goal were taken in consideration for comparison between the variants.\\\n",
        "The table below reports a summary of the results:\n",
        "|                                | S5    | S15   | Dark-S5 | Dark-S15 |\n",
        "|--------------------------------|-------|-------|---------|----------|\n",
        "| **Mean reward (success rate)** |  0.95 |  0.68 |   0.86  |   0.02   |\n",
        "| **Mean steps**                 | 11.94 | 26.81 |  15.02  |   39.5   |\n",
        "\n",
        "The results showed that, as expected, the agent performed better in the smaller environment, even in the \"Dark\" variant, where the agent sees only the adjacent cells; the reduced observability implied a decrease of the success rate and an increased mean number of steps in the \"Dark\" variants with respect to the normal counterparts.\\\n",
        "It has been seen that the success rate drops whenever a more \"intelligent\" exploration of the environment is needed (the exploration embedded in the knowledge base just picks a feasible direction in a clockwise manner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Conclusions**\n",
        "The project showed that a knowledge based agent is able to successfully complete a task exploiting the informations given by the nature of the environment, but the partial observability and the need for an intelligent form of search limit the efficiency and even the ability to reach the goal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Appendix**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Relationship with the course**\n",
        "The project focuses on the area of first order logic and (indirectly) inference. In particular the building of a knowledge base from the informations given by the problem/environment and the subsequent exploitation of the knowledge base to resolve a specific problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Github**\n",
        "The GitHub repository can be found at the following link [https://github.com/RiccardoParente/AIF-Project](https://github.com/RiccardoParente/AIF-Project)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
